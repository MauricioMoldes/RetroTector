import re
import json

from typing import Iterator, Tuple

###############################################################################

class FileReader:
    """State objects that allows to iteratively read the file line by line.
    """
    def __init__(self, filename: str):
        with open(filename, 'r', encoding='utf8') as datafile:
            data_lines = datafile.read().splitlines()
        
        self.file_line_iterator = (line for line in data_lines)
        self.curr_line = next(self.file_line_iterator)
    

    def read_next_line(self) -> str:
        self.curr_line = next(self.file_line_iterator)
        if self.curr_line.strip().startswith("Broken"):
            return self.read_next_line()
        # print(self.curr_line)                                # debug
        return self.curr_line
    

    def get_curr_line(self) -> str:
        return self.curr_line


    def skip_empty(self, iteration_threshold: int=30) -> str:
        clean_curr = self.curr_line.strip()
        i = 0
        while clean_curr == "" or clean_curr == "::":
            i += 1
            if i >= iteration_threshold:
                error_msg = "Empty line skip iteration limit "
                raise ValueError(f"{error_msg}({iteration_threshold}) reached.")
            
            clean_curr = self.read_next_line().strip()




###############################################################################
# Defining types

LTR_entry = dict[str, bool or int or float or str]
LTR_entries = [LTR_entry]

retrov_type_prob = dict[str, float]

domain_entry = {
    "idx": int or None,
    "type": str,
    "origin": str,
    "hotspot": int,
    "frame": int,
    "pos_init": int,
    "pos_fin": int,
    "match_input": str,
    "reference_match": str,
    "n_bases": int
}

subgene_entry = {
    "name": str,
    "type": str,
    "score": int,
    "hotspot": int,
    "domains": [domain_entry]
}
subgene_entries = [subgene_entry]

motif_hit = {'pos_init': int, 'pos_end': int, 'score': int}
motif_hits = [motif_hit]
all_motif_hits = dict[str, motif_hits]

chain_entry = dict[str, (str or 
                        int or 
                        retrov_type_prob or
                        subgene_entries or
                        LTR_entries or
                        motif_hits
                        )
                    ]

###############################################################################
# Header

def grab_header(file_readr: FileReader) -> dict[str,str]:
    """Parses the header of files generated by retrotector.

    Args:
        file_rear (FileReader): State object representing the retrotector file.
    
    Returns:
        (dict[str, str]): Metadata present in the header of the retrotector
            file.
    """
    header_pattern = r"^(\w+): ([^\s]+)$"
    
    parsed_header = {}
    header_line = re.fullmatch(header_pattern, file_readr.get_curr_line())
    while header_line:
        header_key, header_value = header_line.groups()
        if header_key not in parsed_header:
            parsed_header[header_key] = header_value
        else:
            raise KeyError("Repeated parameter in the header of file.")
        header_line = re.fullmatch(header_pattern, file_readr.read_next_line())
    
    return parsed_header


###############################################################################
# soloLTRs

def gen_soloLTR_fields_pattern() -> str:
    """Generates the regex string that parses all the fields of the soloLTR
    lines present in the file generated by retrotector.

    Returns:
        (str) Parsing regex for soloLTR lines.
    """
    border_location = r"[(](?P<init_idx>[0-9]+)-(?P<fin_idx>[0-9]+)[)] "
    full_location = r"(?P<peak_loc>[0-9]+) " + border_location
    polyAdenyl = r"(?P<adenylation_seq>[ATCGatcg]+)[(](?P<adenylation_loc>[0-9]+|-)[)]"

    score_pattern = lambda x: f"(?P<{x}_score>"+r"[0-9]+(?:\.[0-9]+)?" + ")"
    capt_score_n_dist = lambda x: f"{score_pattern(x)}[(](?P<{x}_loc>[0-9]+)[)]"

    def make_field(field_name, only_score=False):
        intro = field_name + ":"
        if only_score:
            return intro + score_pattern(field_name)
        return intro + capt_score_n_dist(field_name) 

    structure = [
        ("U5NN", False),
        ("GT", True),
        ("U3NN", False),
        ("TATAA", False),
        ("MEME50", False),
        ("Mot1", False),
        ("Mot2", False),
        ("Trans", True),
        ("CpG", True),
        ("Spl8", True)
    ]
    pattern_of_fields = ";".join(map(lambda x: make_field(*x), structure))
    TSDs = r"_(?P<TSD5>[atcg]+/[atcg]+)<>(?P<TSD3>[atcg]+/[atcg]+)"

    pattern = "^" + full_location + polyAdenyl + ";" + pattern_of_fields + ";"
    pattern += TSDs + "$"
    return re.compile(pattern)


def parse_soloLTR_lines(file_readr: FileReader,
                        soloLTR_pattern: str,
                        soloLTRs: LTR_entries,
                        primary: bool):
    """Parses the scores and locations of each predicted soloLTR generated by
    the LTRID script of retrotector of one particular set of soloLTRs.

    Makes in_place alterations to the soloLTRs object.

    Args:
        file_readr (FileReader): State object representing the retrotector file.
        soloLTR_pattern (str): Regex string that captures the fields of the solo
            LTR entry.
        soloLTRs (LTR_entries): Resulting parsed soloLTR entries.
        primary (bool): flag indicating if this candidate soloLTR corresponds to
            a primary or secondary candidate.
    """
    
    line = file_readr.read_next_line()
    while line != "::":
        parsed_line = re.fullmatch(soloLTR_pattern, line)
        if not parsed_line:
            error_str = "Problem with parsing of soloLTRs line."
            error_str += " Pattern doesn't match with line:\n"
            error_str += line
            raise ValueError(error_str)
        
        parsed_fields = parsed_line.groupdict()
        parsed_fields['primary'] = primary
        for key in parsed_fields.keys():
            if key.endswith("_loc") or key.endswith("_idx"):
                if parsed_fields[key] != "-":
                    parsed_fields[key] = int(parsed_fields[key])
            elif key.endswith("_score"):
               parsed_fields[key] = float(parsed_fields[key]) 
        soloLTRs.append(parsed_fields)
        
        line = file_readr.read_next_line()


def grab_soloLTRs(file_readr: FileReader) -> LTR_entries:
    """Parses all soloLTRs of a set HERV candidates.

    Args:
        file_readr (FileReader): State object representing the retrotector file.
    
    Returns:
        (LTR_entries) All the parsed soloLTR entrieds.
    """
    
    curr_line = file_readr.get_curr_line()
    soloLTR_fields_pattern = gen_soloLTR_fields_pattern()

    soloLTRs = []
    keep_iterating = True
    while keep_iterating:
        if curr_line == "::":
            pass
        elif curr_line == "PSingleLTRs::":
            parse_soloLTR_lines(file_readr, soloLTR_fields_pattern,
                                    soloLTRs, True)
        elif curr_line == "SSingleLTRs::":
            parse_soloLTR_lines(file_readr, soloLTR_fields_pattern,
                                    soloLTRs, False)
        else:
            keep_iterating = False
    
        if keep_iterating:
            curr_line = file_readr.read_next_line()
    return soloLTRs


###############################################################################
# Parse full-length


######################################
# Parsing ORFs of the proviral genes #
######################################

def _parse_chain_type_probs(file_readr: FileReader) -> retrov_type_prob:
    """Parses a little table of probabilities of the chain, corresponding to a
    HERV candidate, being of each possible retrovirus class.

    Args:
        file_readr (FileReader): State object representing the retrotector file.
    
    Returns:
        (retrov_type_prob) Parsed probabilities of the candidate HERV being of
            each retrovirus class.
    """
    type_probs = {}

    pattern = r"^\s+([A-Z]+):(-?[0-9]+\.[0-9]+)$"
    matched_line = re.fullmatch(pattern, file_readr.get_curr_line())
    while matched_line is not None:
        type_probs[matched_line.group(1)] = float(matched_line.group(2))
        matched_line = re.fullmatch(pattern, file_readr.read_next_line())

    return type_probs


def _parse_subgene_domain(file_readr: FileReader
                        ) -> domain_entry:
    """Parses a domain of the viral genes.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (domain_entry): Parsed candidate domain information.
    """
    poss_idx = lambda x: int(x) if len(x) > 0 else None
    motif = {}
    fst_line_pattern = r"^\s+[53]*[A-Z]+([0-9]*):([A-Z]+) [(](.*)[)]: Score="
    fst_line_pattern += r"([0-9]+) at ([0-9]+) frame ([0-9]) [[]([0-9]+)-([0-9]+)[]]$"
    fst_line_motif = re.fullmatch(fst_line_pattern, file_readr.get_curr_line())
    motif['idx'] = poss_idx(fst_line_motif.group(1))
    motif['type'] = fst_line_motif.group(2)
    motif['origin'] = fst_line_motif.group(3)
    motif['score'] = int(fst_line_motif.group(4))
    motif['hotspot'] = int(fst_line_motif.group(5))
    motif['frame'] = int(fst_line_motif.group(6))
    motif['pos_init'] = int(fst_line_motif.group(7))
    motif['pos_fin'] = int(fst_line_motif.group(8))

    second_line_pattern = r"^\s+(.*) scored against$"
    motif['match_input'] = re.fullmatch(second_line_pattern, 
                                        file_readr.read_next_line()).group(1)

    third_line_pattern = r"^\s+([a-zA-Z]+) [(]([0-9]+) bases[)]$"
    third_match = re.fullmatch(third_line_pattern, file_readr.read_next_line())
    motif['reference_match'] = third_match.group(1)
    motif['n_bases'] = int(third_match.group(2))

    file_readr.read_next_line()
    return motif


def _parse_subgene(file_readr: FileReader) -> subgene_entry:
    """Parses the contents of a candidate subgene.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        Parsed contents of a candidate subgene.
    """
    subgene_info = {}
    start_subgene_pattern = r"^SubGene (\w+), type ([A-Z]*), score=([0-9]+) , hotspot ([0-9]+)$"
    start_subgene_info = re.fullmatch(start_subgene_pattern,
                                        file_readr.get_curr_line()
                                    )
    subgene_info['name'] = start_subgene_info.group(1)
    subgene_info['type'] = start_subgene_info.group(2)
    subgene_info['score'] = int(start_subgene_info.group(3))
    subgene_info['hotspot'] = int(start_subgene_info.group(4))

    file_readr.read_next_line()
    subgene_info['domains'] = []
    while re.fullmatch(r"^\s+[53]*[A-Z]+[0-9]*:.*$", file_readr.get_curr_line()):
        parsed_motifs = _parse_subgene_domain(file_readr)
        subgene_info['domains'].append(parsed_motifs)

    return subgene_info


def _parse_multiple_subgenes(file_readr: FileReader) -> subgene_entries:
    """Parses multiple candidate subgenes.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (subgene_entries) Parsed contents of multiple candidate subgenes.
    """
    results = []
    curr_line = file_readr.get_curr_line()
    while curr_line.startswith("SubGene"):
        results.append(_parse_subgene(file_readr))
        curr_line = file_readr.get_curr_line()
    
    file_readr.skip_empty()
    return results



############################
# Parsing small motif hits #
############################

def _parse_motif_hit_locs(file_readr: FileReader) -> motif_hits:
    """Parses all the hits of a specific motif type.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (motif_hits) Parsed locations and scores of the detected motif hits.
    """
    motif_positions = []

    motif_loc_pattern = r"^(-?[0-9]+) (-?[0-9]+) (-?[0-9]+)$"
    loc_match = re.fullmatch(motif_loc_pattern, file_readr.get_curr_line())
    while loc_match is not None:
        motif_positions.append({
            'pos_init': int(loc_match.group(1)),
            'pos_end': int(loc_match.group(2)),
            'score': int(loc_match.group(3))
        })
        loc_match = re.fullmatch(motif_loc_pattern,file_readr.read_next_line())
    
    if file_readr.get_curr_line() == "::":
        file_readr.read_next_line()
    
    return motif_positions


def _parse_motif_hits(file_readr: FileReader) -> all_motif_hits:
    """Parses all the motif hits and organizes them based on the motif type.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (all_motif_hits): Parsed and organized motif hits according to the type
            of motif.
    """
    
    motif_reg = dict()
    motif_header_pattern = re.compile(r"[PS][0-9]+([a-zA-Z]+)MotifHits::")
    motif_match = re.fullmatch(motif_header_pattern, file_readr.get_curr_line())
    while motif_match is not None:
        file_readr.read_next_line()
        motif_type = motif_match.group(1) + "_motifs"
        motif_reg[motif_type] = _parse_motif_hit_locs(file_readr)
        motif_match = re.fullmatch(motif_header_pattern,
                                    file_readr.get_curr_line()
                                    )
    return motif_reg


##################
#  Parsing LTRs  #
##################


def _parse_LTR_field(file_readr: FileReader,
                        name:str,
                        pat:str,
                        optional:bool=False
                    ) -> re.Match:
    """Checks if a field follows the structure of an LTR field with the provided
    structure.

    Args:
        file_readr (FileReader): State object representing the retrotector file.
        name (str): Name of the LTR field.
        pattern (str): Pattern of the groups that are to be captured.
        optional (str, optional): Flag identifying if the particular field
            always exists (the default option) or if it is possible that in some
            cases it isn't there. Default value is False.

    Returns:
        (re.Match) Match object resulting from matching a structure of a regex
            of an LTR field.
    
    Raises:
        ValueError: In case, the current line of the file doesn't match the
            provided structure of an LTR field and the field is mandatory (not
            optional). 
    """
    m_res = re.fullmatch(r"^\s+" + f"{name}: {pat}$",
                            file_readr.get_curr_line())
    if m_res is None and not optional:
        err_msg = f"Couldn't find {name} field in LTR section. In current line:"
        err_msg += "\n\t\'" + file_readr.get_curr_line() + "\'"
        raise ValueError(err_msg)
    
    elif m_res is not None:
        file_readr.read_next_line()
        return m_res 


def _parse_LTR_details(file_readr: FileReader) -> LTR_entry:
    """Parses either the 5' or the 3' LTR of a chain corresponding to a HERV
    candidate.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (LTR_entry) Parsed content of the LTR of a HERV candidate.
    """

    start_LTR = re.fullmatch(r"^([PS])([0-9]+)_([53])LTR::$", 
                                file_readr.get_curr_line()
                            )
    if start_LTR is None:
        return None

    ltr_info = {
        'primary': start_LTR.group(1) == 'P',
        'candidate_idx': int(start_LTR.group(2)),
        'LTR_type': start_LTR.group(3)
    }

    fl = r"[0-9]+\.[0-9]+"

    mtx_pat = lambda name, pat, opt=False: _parse_LTR_field(file_readr, name,
                                                            pat, opt)

    def modifier(name: str):
        ltr_info[name + "_score"] = float(mtx_pat(name, f"({fl}) {fl}")
                                            .group(1)
                                    )
    
    def loc_n_score(name: str):
        lns_res = mtx_pat(name, f"({fl}) {fl} ([0-9]+)")
        ltr_info[name + "_score"] = float(lns_res.group(1))
        ltr_info[name + "_idx"] = int(lns_res.group(2))

    file_readr.read_next_line()
    ltr_info['factor_score'] = float(mtx_pat("ScoreFactor", f"({fl})").group(1))
    ltr_info['virus_genus'] = mtx_pat("VirusGenus", "([A-Z]+)").group(1)

    opt_res = mtx_pat("SimilarityStart", "([0-9]+)", opt=True)
    if opt_res is not None:
        ltr_info['SimilarityStart'] = int(opt_res.group(1))
    
    ltr_info['init_idx'] = int(mtx_pat("First", "([0-9]+)").group(1))
    ltr_info['fin_idx'] = int(mtx_pat("Last", "([0-9]+)").group(1))

    opt_res = mtx_pat("SimilarityEnd", "([0-9]+)", opt=True)
    if opt_res is not None:
        ltr_info['SimilarityEnd'] = int(opt_res.group(1))

    hotspot = mtx_pat("Hotspot", f"{fl} {fl} ([0-9]+) ([ATCGatcg]+|-)")
    ltr_info['adenylation_loc'] = int(hotspot.group(1))
    ltr_info['adenylation_seq'] = hotspot.group(2)

    loc_n_score("U5NN")
    modifier("GTModifier")
    loc_n_score("U3NN")
    loc_n_score("TATAA")
    loc_n_score("MEME50")
    loc_n_score("Motifs1")
    loc_n_score("Motifs2")
    modifier("Transsites")
    modifier("CpGModifier")
    modifier("Spl8Modifier")
    mtx_pat("ShortDescription", ".*")

    opt_res = mtx_pat("Limiters", "(.*)", opt=True)
    if opt_res is not None:
        ltr_info['Limiters'] = opt_res.group(1)
    
    file_readr.read_next_line()
    return ltr_info
    

def _parse_full_insertion_LTRs(file_readr: FileReader
                                ) -> LTR_entries:
    """Parses both, either or none of the 5' or the 3' LTR of a chain
    corresponding to a HERV candidate.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (LTR_entries) Parsed content of the both, either or none of the LTRs of
            a HERV candidate.
    """
    ltr_5 = _parse_LTR_details(file_readr)
    if ltr_5 is None:
        return []
    
    ltr_3 = _parse_LTR_details(file_readr)
    if ltr_3 is None:
        return [ltr_5]
    return [ltr_5, ltr_3]


def _parse_chain(file_readr: FileReader) -> chain_entry:
    """Parses the contents of the chain of a HERV candidate including all its
    elements and subelements.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (chain_entry): Parsed contents of the chain of a HERV candidate.
    """
    chain_info = {}

    start_chain = re.fullmatch(r"^Chain([PS])([0-9]+)::$", file_readr.get_curr_line())
    if start_chain is None:
        return None
    chain_info['type_of_chain'] = start_chain.group(1)
    chain_info['chain_level'] = int(start_chain.group(2))

    file_readr.read_next_line()
    chain_info['type_probs'] = _parse_chain_type_probs(file_readr)
    
    file_readr.skip_empty()
    chain_info['chain_start_idx'] = int(file_readr.get_curr_line())
    chain_info['chain_end_idx'] = int(file_readr.read_next_line())
    type_score = re.fullmatch(r"^\s+Type ([A-Z])+ Score= ([0-9]+)$",
                                file_readr.read_next_line() )
    chain_info['retrovirus_type'] = type_score.group(1)
    chain_info['score'] = int(type_score.group(2))

    file_readr.read_next_line()
    chain_info['subgenes'] = _parse_multiple_subgenes(file_readr)

    if file_readr.get_curr_line().startswith("Integration sites"):
        chain_info['integration_sites'] = file_readr.get_curr_line().split(" ")[2]
        file_readr.read_next_line()
        file_readr.skip_empty()
    
    if file_readr.get_curr_line().startswith("Missing"):
        file_readr.read_next_line()
        file_readr.skip_empty()
    
    chain_info['LTRs'] = _parse_full_insertion_LTRs(file_readr)
    
    chain_info.update(_parse_motif_hits(file_readr))
    return chain_info


def parse_PseuGID(file_readr: FileReader) -> list[chain_entry]:
    """Parses all consecutive chains available in the file from the starting
    position.
    
    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (list[chain_entry]) All consecutive chains from the given position in
            the file.
    """
    chains = []
    while file_readr.get_curr_line().startswith("Chain"):
        chains.append(_parse_chain(file_readr))
    return chains


###############################################################################
# Footer

def _parse_footer_params(parsed_footer: dict[str, str],
                        file_readr: FileReader):
    """Parses multiple lines of the footer, where the pattern is constant.
    
    Makes inplace alterations to the `parsed_footer` object.

    Args:
        parsed_footer (dict[str, str]): Parsed footer so far.
        file_readr (FileReader): State object representing the retrotector file.
    """
    n_iterations = 0
    curr_line = file_readr.get_curr_line()
    while not curr_line.startswith("{   "):
        n_iterations += 1
        if n_iterations > 30:
            raise ValueError("Footer is misformatted.")
        
        linematch = re.fullmatch(r"^[{] (\w+): (.*)$", curr_line)
        parsed_footer[linematch.group(1)] = linematch.group(2)
        curr_line = file_readr.read_next_line()
    
    file_readr.read_next_line()


def grab_footer(file_readr: FileReader) -> dict[str, str]:
    """Parses the footer of the RetroTector output file.

    Args:
        file_readr (FileReader): State object representing the retrotector file.

    Returns:
        (dict[str, str]) Parsed footer.
    """
    
    parsed_footer = {}
    curr_line = file_readr.get_curr_line()
    if curr_line == "::":
        curr_line = file_readr.read_next_line()
    
    if not curr_line.startswith("{ Execution"):
        raise ValueError("Trying to parse footer, but didn't find footer")

    def _insert_entry(entry_key: str, pattern: str) -> str:
        c_line = file_readr.get_curr_line()
        parsed_footer[entry_key] = re.fullmatch(pattern, c_line).group(1)
        file_readr.read_next_line()

    duration_pattern = r"^[{] Execution time was ([0-9]+) milliseconds$"
    _insert_entry("execution_duration", duration_pattern)
    
    executer_pattern = r"^[{] Created by ([a-zA-Z]+) with parameters$"
    _insert_entry('executer', executer_pattern)
    
    _parse_footer_params(parsed_footer, file_readr)

    belongs_pattern = r"^[{] Belongs in (.*)$"
    _insert_entry("script_input", belongs_pattern)

    run_meta_pattern = r"^[{] Created (.*) under RetroTector version ([0-9a-z\.]+)$"
    meta_match = re.fullmatch(run_meta_pattern, file_readr.get_curr_line())
    parsed_footer['run_datetime'] = meta_match.group(1)
    parsed_footer['retrotector_version'] = meta_match.group(2)

    db_meta_pattern = r"^[{] using ([\w]+:[\w]+) last modified (.*)$"
    db_match = re.fullmatch(db_meta_pattern, file_readr.read_next_line())
    parsed_footer['db_name'] = db_match.group(1)
    parsed_footer['db_last_modified_datetime'] = db_match.group(2)

    return parsed_footer


################################################################################
    
def read_parse_write(read_fname: str,
                        output_fname: str
                    ):
    """Parses the entire output file of the SelectedChains script from
    RetroTector.

    Args:
        read_fname (str): Path and name of the output file of SelectedChains.
        output_fname (str): Path and name of the file where to store the
            resulting JSON file with the results of parsing the SelectedChains
            results.
    """
    
    fr = FileReader(read_fname)

    parsed_contents = {
            'header': grab_header(fr), 
            'soloLTRs': grab_soloLTRs(fr),
            'pseuGID': parse_PseuGID(fr),
            'footer': grab_footer(fr)
        }
    
    if not output_fname.endswith(".json"):
        output_fname += ".json"

    with open(output_fname, 'w', encoding='utf8') as datafile:
        datafile.write(json.dumps(parsed_contents))


###############################################################################

if __name__ == '__main__':
    import argparse

    parser = argparse.ArgumentParser(
                    prog='RetroTector__SelectedChains__parser',
                    description='This programs parses the output of the SelectedChains script of Retrotector into a JSON file',
                    epilog='Good Luck')
    parser.add_argument('SelectedChains_file',
                        help="Path and name of the output file of SelectedChains"
                        )
    parser.add_argument('Output_JSON',
                        help="Path and name of the output JSON file"
                        )
    args = parser.parse_args()
    read_parse_write(args.SelectedChains_file, args.Output_JSON)

            